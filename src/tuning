# 为分层抽样创建类别
df['age_group_stratify'] = pd.cut(df['age'], bins=[0, 20, 30, 40, 50, 80], labels=['0-20', '21-30', '31-40', '41-50', '51+'])
df['stratify_col'] = df['sex'].astype(str) + '_' + df['age_group_stratify'].astype(str)

# 定义自变量X和因变量y
# 包括所有主观体验特征以及年龄和性别
X_features = [
    'age', 'sex', 
    'autonomy_freedom', 'autonomy_interesting', 'autonomy_options',
    'competence_matched', 'competence_capable', 'competence_competent',
    'related_important', 'related_fulfilling', 'related_not_close',
    'enjoyment_fun', 'enjoyment_attention', 'enjoymen_boring', 'enjoyment_enjoyed',
    'extrinsic_avoid', 'extrinsic_forget', 'extrinsic_compelled', 'extrinsic_escape',
    'Hours'
]
X = df[X_features]
y = df['happiness_value']

# --- 1. 数据分割 ---
# 我们只需要训练集来进行交叉验证调参
# 按照80%的比例分出训练集
X_train, _, y_train, _ = train_test_split(
    X, y, train_size=0.80, random_state=42, stratify=df['stratify_col']
)

print(f"Using a training set of size: {len(X_train)} for hyperparameter tuning.")
print("-" * 30)


# --- 2. 随机森林 (Random Forest) 超参数调优 ---
print("Starting Hyperparameter Tuning for Random Forest...")
print("This may take several minutes...")

# 定义参数网格
param_grid_rf = {
    'n_estimators': [100, 200, 300],        
    'max_depth': [10, 20, 30, None],       
}

# 初始化随机森林回归器
rf = RandomForestRegressor(random_state=42)

# 初始化GridSearchCV
grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, 
                              cv=5, n_jobs=-1, scoring='neg_mean_squared_error', verbose=1)

# 在训练集上进行拟合
grid_search_rf.fit(X_train, y_train)

# 打印出你需要填入Table 1的结果
print("\n" + "="*40)
print("RESULTS FOR RANDOM FOREST (TABLE 1)")
print("="*40)
print("Optimal Hyperparameters Found:")
print(grid_search_rf.best_params_)
print(f"Best cross-validation MSE: {-grid_search_rf.best_score_:.4f}")
print("="*40 + "\n")


# --- 3. XGBoost 超参数调优 ---
print("\nStarting Hyperparameter Tuning for XGBoost...")
print("This may also take several minutes...")

# 定义参数网格
param_grid_xgb = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],               
    'learning_rate': [0.01, 0.05, 0.1],   
    'subsample': [0.7, 0.8, 0.9]          
}

# 初始化XGBoost回归器
xgb = XGBRegressor(random_state=42, objective='reg:squarederror')

# 初始化GridSearchCV
grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, 
                               cv=5, n_jobs=-1, scoring='neg_mean_squared_error', verbose=1)

# 在训练集上进行拟合
grid_search_xgb.fit(X_train, y_train)

# 打印出你需要填入Table 2的结果
print("\n" + "="*40)
print("RESULTS FOR XGBOOST (TABLE 2)")
print("="*40)
print("Optimal Hyperparameters Found:")
print(grid_search_xgb.best_params_)
print(f"Best cross-validation MSE: {-grid_search_xgb.best_score_:.4f}")
print("="*40)
